{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Packages"
      ],
      "metadata": {
        "id": "gv0gtnqSxc73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FyKNzst-wCdw"
      },
      "outputs": [],
      "source": [
        "# Import all other necessary libraries\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# For classification we will be using Gaussian model training\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Accuracy score is required to check the correctness of the predictions\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Preparation"
      ],
      "metadata": {
        "id": "YG2mOpfMxfIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function with all words\n",
        "\n",
        "def make_Dictionary(root_dir):\n",
        "  all_words = []\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words\n",
        "  dictionary = Counter(all_words)\n",
        "  list_to_remove = list(dictionary)\n",
        "\n",
        "# Remove all non-alpha numeric values. Additionally remove items with length = 1.\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False:\n",
        "      del dictionary[item]\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item]\n",
        "# Dictionary returns a list of 3000 of the most common words\n",
        "  dictionary = dictionary.most_common(3000)\n",
        "  return dictionary\n"
      ],
      "metadata": {
        "id": "C8iAWBe2xhym"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Features of the dataset"
      ],
      "metadata": {
        "id": "Xncp0RfpyA3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to classify email as spam or not\n",
        "\n",
        "# Step 1: Create a matrix\n",
        "def extract_features(mail_dir):\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "  features_matrix = np.zeros((len(files),3000))\n",
        "  train_labels = np.zeros(len(files))\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "# Step 2: Split and count words \n",
        "  for fil in files:\n",
        "    with open(fil) as fi:\n",
        "      for i, line in enumerate(fi):\n",
        "        if i ==2:\n",
        "          words = line.split()\n",
        "          for word in words:\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary):\n",
        "              if d[0] == word:\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word)\n",
        "      train_labels[docID] = 0;\n",
        "      filepathTokens = fil.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "  return features_matrix, train_labels                "
      ],
      "metadata": {
        "id": "82XTwcj1xrBh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount to Google Drive and set File Path"
      ],
      "metadata": {
        "id": "cDhpX48ay0pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTahtqDhxyOu",
        "outputId": "a838b709-7ecb-44de-c369-3f0981dbb7a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the path of the train_mails and test-mails folders\n",
        "\n",
        "TRAIN_DIR = '/content/gdrive/MyDrive/CA02-new/train-mails'\n",
        "TEST_DIR = '/content/gdrive/MyDrive/CA02-new/test-mails'\n"
      ],
      "metadata": {
        "id": "EjfUzWSTx6Aj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Train file to Train data and then Test for Accuracy"
      ],
      "metadata": {
        "id": "tY-VdeL2Gy63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary using the train data.\n",
        "\n",
        "dictionary = make_Dictionary(TRAIN_DIR)"
      ],
      "metadata": {
        "id": "uCc1KuK6yQ_V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"reading and processing emails from TRAIN and TEST folders\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMh7X6D-FBmt",
        "outputId": "25de02a0-65ce-476a-f6c3-cb12cbfc5667"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# features matrix for training dataset\n",
        "\n",
        "features_matrix, labels = extract_features(TRAIN_DIR)"
      ],
      "metadata": {
        "id": "UlFLZOZvFEEo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features matrix for testing dataset\n",
        "\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR)"
      ],
      "metadata": {
        "id": "ev5vdrPiFFqG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GaussianNB()"
      ],
      "metadata": {
        "id": "WVXCi0cM7coZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Training Model using Gaussian Naive Bayes algorithm assuming a Normal Distribution of 3000 most common words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evkPlu4PF4vh",
        "outputId": "b3f36a9e-5481-4217-aaec-87c23b8b042f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model using Gaussian Naive Bayes algorithm assuming a Normal Distribution of 3000 most common words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using train-mails dataset\n",
        "model.fit(features_matrix, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5CqQGC_2sGY",
        "outputId": "12ca1691-f70b-412a-9793-bb61ce242538"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Training completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2NJQSXgF-ke",
        "outputId": "e4e52a41-8911-48e4-af3a-1dc625c05318"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"testing trained model to predict Test Data labels\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGaz3lIH3__C",
        "outputId": "804ba3c9-8a3a-4a11-c7aa-ce272bad7871"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing trained model to predict Test Data labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = model.predict(test_features_matrix)\n",
        "print (\"Completed classification of the Test Data. Now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkULFFB-CwOL",
        "outputId": "08f2c8c9-dd6b-4949-bee5-35614451056c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed classification of the Test Data. Now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_score(test_labels, predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8uVPx6hEeU0",
        "outputId": "d121b881-d749-4523-8e23-7febd71ebabc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9615384615384616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The approximate 96% accuracy proves that the model is very well structured however that is too good to be true. This model needs to be re-evaluated to check for potential over fitting in the dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HaiGu4k4fPH",
        "outputId": "0b2f4b53-9407-4021-c3a7-1568c567d933"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The approximate 96% accuracy proves that the model is very well structured however that is too good to be true. This model needs to be re-evaluated to check for potential over fitting in the dataset\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gv0gtnqSxc73",
        "YG2mOpfMxfIo",
        "Xncp0RfpyA3q",
        "cDhpX48ay0pw",
        "tY-VdeL2Gy63"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}